---
title: "Markov Chains"
author: "Anthony Hung"
date: "2019-05-01"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction

Markov chains are models that describe the sequence of possible events for a system in which the probability of each event is dependent only on the event immediately preceeding that event. Markov chains are a staple in computational statistics. Today we will learn the basics behind Markov Chains and their long-run behavior.

## The Markov assumption

The Markov assumption assumes that in order to predict the future behavior of a system, all that is required is knowledge of the present state of the system and not the past state of the system. For example, given a set of times $t_1, t_2, t_3, t_4$ and states $X_1, X_2, X_3, X_4$, under the Markov assumption: 

$$P(X_4=1|X_3=0, X_2=1, X_1=1) = P(X_4=1|X_3=0)$$

In other words, "the past and the future are conditionally independent given the present‚Äù. 
If we have knowledge about the present, then knowing the past does not give us any more information to predict what will happen in the future.

## Components of Markov Chains 


