<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Anthony Hung" />

<meta name="date" content="2019-05-01" />

<title>Markov Chains</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ISTP Summer JC: Statistical Theory & Methods</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/anthonyhung/MSTPsummerstatistics">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<!-- Add a small amount of space between sections. -->
  <style type="text/css">
    div.section {
      padding-top: 12px;
    }
  </style>

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Markov Chains</h1>
<h4 class="author">Anthony Hung</h4>
<h4 class="date">2019-05-01</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-markov-assumption">The Markov assumption</a><ul>
<li><a href="#the-central-dogma-of-biology-as-a-markov-chain">The central dogma of biology as a Markov chain</a></li>
</ul></li>
<li><a href="#components-of-markov-chains">Components of Markov Chains</a><ul>
<li><a href="#example-of-markov-chain">Example of Markov Chain</a></li>
</ul></li>
<li><a href="#long-run-behavior-of-markov-chains-stationary-probabilities">Long run behavior of Markov chains: stationary probabilities</a></li>
<li><a href="#uses-of-markov-chains">Uses of Markov Chains</a></li>
<li><a href="#markov-chain-monte-carlo-mcmc">Markov Chain Monte Carlo (MCMC)</a></li>
<li><a href="#addendum-hidden-markov-models">Addendum: Hidden Markov Models</a><ul>
<li><a href="#components-of-a-hmm">Components of a HMM</a></li>
</ul></li>
<li><a href="#exercises">Exercises:</a></li>
</ul>
</div>

<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2020-06-23
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>MSTPsummerstatistics/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.5.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20180927code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20180927)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20180927code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20180927)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomanthonyhungMSTPsummerstatisticstree2ac74f5a18d8318c3841925ca51b64dd577e6eddtargetblank2ac74f5a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/anthonyhung/MSTPsummerstatistics/tree/2ac74f5a18d8318c3841925ca51b64dd577e6edd" target="_blank">2ac74f5</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomanthonyhungMSTPsummerstatisticstree2ac74f5a18d8318c3841925ca51b64dd577e6eddtargetblank2ac74f5a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .RData
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.DS_Store
    Ignored:    analysis/.RData
    Ignored:    analysis/.Rhistory
    Ignored:    data/.DS_Store

Unstaged changes:
    Modified:   analysis/syllabus.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/cdeb6c5df403543fff38d1f92a2ed87ebbc5723d/docs/markov.html" target="_blank">cdeb6c5</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-06-22
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/14c0094c035d017f8be1e0851c138ae49fcb3daf/docs/markov.html" target="_blank">14c0094</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-06-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/1378fcad8eb1b58e61b70a6ff46517e2fb9b6ad4/docs/markov.html" target="_blank">1378fca</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-06-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/9bb0ed699ed2fe1a2ca05cfd505c6cb7c986860f/docs/markov.html" target="_blank">9bb0ed6</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/2114e6c9aebfa316aab6c7a2676ebdce1bc08ef5/docs/markov.html" target="_blank">2114e6c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/29c91df7cfe6c689a286531fc31948746f830894/docs/markov.html" target="_blank">29c91df</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/a6d0787a18ba58d83f9a0728f8d2a583add8675c/docs/markov.html" target="_blank">a6d0787</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/e18c369e3fcbb64ccf95c695d84510a1fcb0acac/docs/markov.html" target="_blank">e18c369</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-02
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/0e6b6d0fad27510d20b1193d8939bac1d6fc3263/docs/markov.html" target="_blank">0e6b6d0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/markov.html" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/4e089357d0e95411d0a6199b2a4d314567d7088a/docs/markov.html" target="_blank">4e08935</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-03-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/f15db48dbd6a0ea59883ffe6c16b34a3f5c2f4a2/docs/markov.html" target="_blank">f15db48</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-03-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/markov.html" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/5a37a3ece9be5a700915a43c6df6383efe5aa680/docs/markov.html" target="_blank">5a37a3e</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-14
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/96722bdbe5195cb0e43c78b0bc8de5a17af3db56/docs/markov.html" target="_blank">96722bd</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/15ca1f112dabdce101896776b46418dcbb66aa08/docs/markov.html" target="_blank">15ca1f1</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-07-18
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/a3aa9e0d23508c7eecdd5fc5f5a83a3f1f856fc7/docs/markov.html" target="_blank">a3aa9e0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-07-18
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/ceb577eed36a810ffebbf60a524affa541281a33/docs/markov.html" target="_blank">ceb577e</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-07-12
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/6234571134071f3d5abbf6c8093043fabcf63377/analysis/markov.Rmd" target="_blank">6234571</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-07-12
</td>
<td>
commit changes
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/6234571134071f3d5abbf6c8093043fabcf63377/docs/markov.html" target="_blank">6234571</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-07-12
</td>
<td>
commit changes
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/397882ba5bb902738ccf3b8e3dd320b85eeb4bec/docs/markov.html" target="_blank">397882b</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/2debade6b3d2a6dc524f171e5aa30bd2a2156fcb/analysis/markov.Rmd" target="_blank">2debade</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-30
</td>
<td>
commit before republish
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/2debade6b3d2a6dc524f171e5aa30bd2a2156fcb/docs/markov.html" target="_blank">2debade</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-30
</td>
<td>
commit before republish
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/6d3e1c816c22dcdf898173d8e2858c3a3d0238ef/docs/markov.html" target="_blank">6d3e1c8</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/4fcd1d02795634da2ad4fe5a312d4f3cea747633/analysis/markov.Rmd" target="_blank">4fcd1d0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
commit before republish
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/4fcd1d02795634da2ad4fe5a312d4f3cea747633/docs/markov.html" target="_blank">4fcd1d0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
commit before republish
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/c117ef10cb90e0b3b89106a56e0e03762571345a/docs/markov.html" target="_blank">c117ef1</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/c3c7b6e2c616e5e9b36e302b69daebdd1718cae7/analysis/markov.Rmd" target="_blank">c3c7b6e</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
Bayesian
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/c3c7b6e2c616e5e9b36e302b69daebdd1718cae7/docs/markov.html" target="_blank">c3c7b6e</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-28
</td>
<td>
Bayesian
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/b291d24b99263105227f9a3edb002e98252785de/docs/markov.html" target="_blank">b291d24</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-24
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/4e210d641f8ab305d79d5c884528be2e26f028f5/docs/markov.html" target="_blank">4e210d6</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-24
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/c4bdfdc7ed061819bbb246828e4af30054e26b39/docs/markov.html" target="_blank">c4bdfdc</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-22
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/4ce8e8525dac0d35ce6baff65f0d608a139ba63f/analysis/markov.Rmd" target="_blank">4ce8e85</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-21
</td>
<td>
bandersnatch add
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/096760a626cc23032b925ccc238d64c8c991c8c7/docs/markov.html" target="_blank">096760a</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-19
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/193ab25f3669113690dde6ae45a377acf5ac68df/analysis/markov.Rmd" target="_blank">193ab25</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-19
</td>
<td>
additions to complete mult testing
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/193ab25f3669113690dde6ae45a377acf5ac68df/docs/markov.html" target="_blank">193ab25</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-19
</td>
<td>
additions to complete mult testing
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/da98ae8f6248396dfbe60499fbe402a628903369/docs/markov.html" target="_blank">da98ae8</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-18
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/239723ec3a2b2292484af14f0a209ba997b6cc7b/analysis/markov.Rmd" target="_blank">239723e</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-08
</td>
<td>
Update learning objectives
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/2ec7944f6cbaafe7eae338dc3e788fd1ee8b5a25/docs/markov.html" target="_blank">2ec7944</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-06
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/d45dca418110b00b669ce0fc53b3824986a0e826/analysis/markov.Rmd" target="_blank">d45dca4</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-06
</td>
<td>
Republish
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/d45dca418110b00b669ce0fc53b3824986a0e826/docs/markov.html" target="_blank">d45dca4</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-06
</td>
<td>
Republish
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ee754863c0a68a5f471f3f8d253974ec9c5dba8f/analysis/markov.Rmd" target="_blank">ee75486</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-05-05
</td>
<td>
Build site.
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<style>
hide {
  background-color: #d6d6d6;
  color: #d6d6d6;
}
hide:hover {
  background-color: white;
  color: black;
}
</style>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Markov chains are stochastic processes that describe the sequence of possible countable events for a system in which the probability of transitions from each event to the next is dependent only on the event immediately preceeding that event. Markov chains are a staple in computational statistics. Our objective today is to learn the basics behind discrete time Markov Chains and their long-run behavior.</p>
</div>
<div id="the-markov-assumption" class="section level2">
<h2>The Markov assumption</h2>
<p>The Markov assumption assumes that in order to predict the future behavior of a system, all that is required is knowledge of the present state of the system and not the past state of the system. For example, given a set of times <span class="math inline">\(t_1, t_2, t_3, t_4\)</span> and states <span class="math inline">\(X_1, X_2, X_3, X_4\)</span>, under the Markov assumption or Markov property:</p>
<p><span class="math display">\[P(X_4=1|X_3=0, X_2=1, X_1=1) = P(X_4=1|X_3=0)\]</span></p>
<p>In other words, “the past and the future are conditionally independent given the present”. If we have knowledge about the present, then knowing the past does not give us any more information to predict what will happen in the future. Another term that is commonly used to describe Markov chains is “memorylessness.”</p>
<p><strong>Question:</strong> What distribution that we have discussed in probability is also described by the property of “memorylessness”?</p>
<p><hide> The Poisson distribution is memoryless. You can set any point along a Poisson process as time 0 and have it be another Poisson process. </hide></p>
<div id="the-central-dogma-of-biology-as-a-markov-chain" class="section level3">
<h3>The central dogma of biology as a Markov chain</h3>
<p>The central dogma of biology describes how information moves from DNA to RNA to Protein.</p>
<p><span class="math display">\[DNA \rightarrow RNA \rightarrow Protein\]</span></p>
<p>The assumption under the central dogma is that information flows only in one direction, and never backwards. Under a Markov chain model of the central dogma, the amount of RNA you observe in a cell is some function of the genetic variations seen at the DNA sequence level (in coding and noncoding regulatory regions), and the amount of protein you see in the cell is some function of the abundance of RNA transcripts in the cell coding for that protein. If you know the amount of RNA in the cell, then knowing the underlying DNA sequence of the cell at the gene encoding the protein does not give you more information to better predict the amount of protein in the cell. Obviously, there are exceptions to such a simple model of biology, but in the vast majority of cases this model does a very good job of describing biological networks.</p>
</div>
</div>
<div id="components-of-markov-chains" class="section level2">
<h2>Components of Markov Chains</h2>
<p>A Markov chain describing the states that a time-dependent random variable X_t takes on at each time-step t is fully determined by two elements:</p>
<ol style="list-style-type: decimal">
<li><p>A transition probability matrix (P) that defines the transition probabilities between each pair of states i and j (<span class="math inline">\(P_{ij} = P(X_t = j | X_{t-1}=i)\)</span>).</p></li>
<li><p>An initial probability distribution vector (<span class="math inline">\(x_0\)</span>) containing values for <span class="math inline">\(P(X_0 = i)\)</span> for each state i.</p></li>
</ol>
<p>With these two quantities, we can compute the probability that a Markov chain takes on any given state at any given time.</p>
<div id="example-of-markov-chain" class="section level3">
<h3>Example of Markov Chain</h3>
<p>Let’s explore an example of a Markov Chain. For example, let’s say that we live in a world where the weather is very predictable. There are only 3 states of weather (X=s when it’s Sunny, X=c when it’s Cloudy, and X=r when it’s rainy), and the weather is always the same for the whole day. On a day when it is sunny, the probability that it will be sunny the next day is 0.6, the probabilty that it will be cloudy the next day is 0.3, and the probability that it will be rainy the next day is 0.1. On a day when it is cloudy, the probability that the next day is sunny is 0.2, the probability that the next day is cloudy is 0.3, and the probability that the next day is rainy is 0.5. On a day when it is rainy, the probabilty that the next day will be rainy is 0.5, the probability that next day will be sunny is 0.4, and the probability that the next day will be cloudy is 0.1. A visual depiction of these transition probabilities can be found here: <a href="https://stackoverflow.com/questions/36574814/creating-three-state-markov-chain-plot" class="uri">https://stackoverflow.com/questions/36574814/creating-three-state-markov-chain-plot</a>. We can also create a transition probability matrix in R, assuming that the order of the states is s,c,r:</p>
<pre class="r"><code>P &lt;- matrix(c(c(0.6,0.2,0.4),c(0.3,0.3,0.1),c(0.1,0.5,0.5)),nrow=3)
P</code></pre>
<pre><code>     [,1] [,2] [,3]
[1,]  0.6  0.3  0.1
[2,]  0.2  0.3  0.5
[3,]  0.4  0.1  0.5</code></pre>
<p>The matrix is constructed with i in the rows, and j in the columns. Each cell is filled in with the values for <span class="math inline">\(P_{ij} = P(X_t = j | X_{t-1}=i)\)</span>. Each of the rows must sum to 1, since the matrix describes all possible transitions.</p>
<p>Let’s also assume that we have an initial probability vector <span class="math inline">\(x_0\)</span>:</p>
<pre class="r"><code>x_0 &lt;- c(0.8, 0.1, 0.1)</code></pre>
<p>In this case, this means on day 0 there is a 0.8 probability that it is sunny, 0.1 probability that it is cloudy, and 0.1 probability that it is rainy. The vector must also sum to 1, since it must fully describe all possible states on day 0.</p>
<p>If we want to compute the probability that on day 1, the weather will be sunny, we must solve the following equation:</p>
<p><span class="math display">\[P(X_1 = sunny) = \sum\limits_i P(X_0 = i)P(X_1 = sunny|X_0 = i)\]</span></p>
<p>We could do this manually using our vector <span class="math inline">\(x_0\)</span> and P:</p>
<p><span class="math display">\[P(X_1 = sunny) = 0.8*0.6 + 0.1*0.2 + 0.1*0.4 = 0.54\]</span></p>
<p>The probability that day 1 is sunny is 0.54. But what if we want to calculate the probability that day 2 is sunny? We would need to first find the state probabilities for all three states for day 1 (repeating what we did above two more times), then plug them in to the following equation:</p>
<p><span class="math display">\[P(X_2 = sunny) = \sum\limits_i P(X_1 = i)P(X_2 = sunny|X_1 = i)\]</span></p>
<p>You can appreciate that manually summing over all possible states would quickly get unwieldy, multiplying the number of calculations you need to perform by 3 for each increasing day.</p>
<p>Fortunately, we can use matrix algebra to do all this multiplying and summing for us. In R, if we would like to calculate <span class="math inline">\(x_1\)</span>, our vector of state probabilities on day 1 is:</p>
<pre class="r"><code>x_0%*%P</code></pre>
<pre><code>     [,1] [,2] [,3]
[1,] 0.54 0.28 0.18</code></pre>
<p>We can do this for any number of days. For example, for the vector of state probabilities after 10 days:</p>
<pre class="r"><code>library(expm) #the expm package allows us to raise a matrix to a power</code></pre>
<pre><code>Loading required package: Matrix</code></pre>
<pre><code>
Attaching package: &#39;expm&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:Matrix&#39;:

    expm</code></pre>
<pre class="r"><code>x_0 %*% (P %^% 10)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411769 0.2352953 0.3235278</code></pre>
<p>Note that in our simple example, you may ask yourself “what if the probabilty that it rains tomorrow depends not only on the weather today, but also yesterday?” You can actually slightly change our Markov chain to account for this! Instead of representing your states as S, C, and R, you can easily imagine changing our states to SS, SC, SR, CS, CC, CR, RS, RC, and RR to now create a Markov chain in which the probability of weather tomorrow only depends on the weather over the past two days. Now you can see why Markov chains are so powerful!</p>
</div>
</div>
<div id="long-run-behavior-of-markov-chains-stationary-probabilities" class="section level2">
<h2>Long run behavior of Markov chains: stationary probabilities</h2>
<p>For a certain class of Markov chains, called ergodic Markov chains (<a href="https://brilliant.org/wiki/stationary-distributions/" class="uri">https://brilliant.org/wiki/stationary-distributions/</a>), there exists a stationary probability distribution, or an equillibrium distribution of possible states that a Markov chain will converge upon after many many iterations. To see what this means, let’s see what the probability distributions are for the weather on the 100th day given our values for P and <span class="math inline">\(x_0\)</span>.</p>
<pre class="r"><code>x_0 %*% (P %^% 100)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411765 0.2352941 0.3235294</code></pre>
<p>What about on the 101st day? 102nd?</p>
<pre class="r"><code>x_0 %*% (P %^% 101)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411765 0.2352941 0.3235294</code></pre>
<pre class="r"><code>x_0 %*% (P %^% 102)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411765 0.2352941 0.3235294</code></pre>
<p>You can see that the probabilities have convereged upon an equillibrium vector which does not change even as we step forward into the future. In fact, this equillibrium or stationary distribution is unique to the transition probability matrix and does not depend on <span class="math inline">\(x_0\)</span>:</p>
<pre class="r"><code>c(1, 0, 0) %*% (P %^% 101)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411765 0.2352941 0.3235294</code></pre>
<pre class="r"><code>c(0, 1, 0) %*% (P %^% 102)</code></pre>
<pre><code>          [,1]      [,2]      [,3]
[1,] 0.4411765 0.2352941 0.3235294</code></pre>
<p>This makes sense because if you go far enough into the future, the current state becomes less and less important and gives you less and less information to predict what the states will look like in the future. If I know it is cloudy today, I can probably do a good job of predicting if it will rain tomorrow. But I probably will not be better at predicting if it will rain 10 years from now compared to if I knew that today was sunny.</p>
<p>If we did not want to simply raise a matrix to a large power in order to find a stationary distribution, eigenvalue decomposition (beyond the scope of this class) could be used to determine the stationary probability.</p>
<p>Note that not all Markov chains will have a unique stationary distribution. For example, consider the following transition matrix describing the transitions between two states:</p>
<pre class="r"><code>matrix(c(0,1,1,0), ncol =2, byrow=F)</code></pre>
<pre><code>     [,1] [,2]
[1,]    0    1
[2,]    1    0</code></pre>
<p>This is called a <em>periodic</em> Markov Chain.</p>
<p>The Markov chain with this transition probability matrix will also not reach a unique stationary distribution. Why?</p>
<pre class="r"><code>matrix(c(0.5,0.5, 0, 0, 0, 0.5, 0.5, 0, 0, 0, 0, 0, 0.3, 0.4, 0.3, 0, 0, 0.3, 0.3, 0.4, 0, 0, 0.3, 0.3, 0.4), ncol =5, byrow=T)</code></pre>
<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]  0.5  0.5  0.0  0.0  0.0
[2,]  0.5  0.5  0.0  0.0  0.0
[3,]  0.0  0.0  0.3  0.4  0.3
[4,]  0.0  0.0  0.3  0.3  0.4
[5,]  0.0  0.0  0.3  0.3  0.4</code></pre>
<p>Markov Chains like these are known as <em>reducible</em> Markov chains.</p>
<p>Markov chains that reach a stationary distribution are Ergodic, or <em>aperiodic</em> and <em>irreducible</em>.</p>
</div>
<div id="uses-of-markov-chains" class="section level2">
<h2>Uses of Markov Chains</h2>
<p>Why do we care about Markov chains? Besides being able to predict the behavior and states of systems, there are many practical applications. For example, if you’ve ever used a smartphone keyboard and seen the suggestions for the next word, you’ve made use of a Markov chain! The subreddit <a href="https://www.reddit.com/r/SubredditSimulator/comments/3g9ioz/what_is_rsubredditsimulator/">/r/SubredditSimulator</a> generates complete posts using Markov Chains created from transition matrices generated using words included in the last 500 submissions in a variety of subreddit communities on reddit.</p>
<p>Perhaps more relevant to us in Biology and Bayesian statistics, Markov chains are an important element of Markov Chain Monte Carlo methods.</p>
</div>
<div id="markov-chain-monte-carlo-mcmc" class="section level2">
<h2>Markov Chain Monte Carlo (MCMC)</h2>
<p>As the name may suggest, MCMC methods bring together two concepts: Markov chains and monte carlo methods.</p>
<ol style="list-style-type: decimal">
<li><p>Markov chains are stochastic processes where future states only depend on the last state (the markov property)</p></li>
<li><p>Monte Carlo methods rely on simulating a large number of random numbers to estimate properties of a distribution. An example is here, where we use monte carlo methods to estimate pi: <a href="https://academo.org/demos/estimating-pi-monte-carlo/" class="uri">https://academo.org/demos/estimating-pi-monte-carlo/</a>. We also use Monte Carlo methods to estimate population means through using sample means. If we were to take a larger and larger number of samples from the population (similar to simulating more and more points on the square), then our estimate of the population mean (the sample mean) would become more and more precice (Question: what mathematical law predicts this behavior? <hide> The Law of Large Numbers </hide>)</p></li>
</ol>
<p>Markov Chain Monte Carlo techniques use Markov chains to sample repeatedly from a complicated or unnamed distribution, then use Monte Carlo methods to estimate properties of that distribution. Why would we ever need to do this? Let’s return to our previous exploration of Bayes theorem</p>
<p>Recall that under Bayes theorem,</p>
<p><span class="math display">\[Posterior\_probability \propto prior\_probability * Likelihood\]</span> Although there are cases where multiplying two distributions (our prior probability distribution and the probability distribution of our likelihood) will result in a posterior probability that is named and well-defined (e.g. the normal distribution, or binomial distribution), many times it will actually result in an unnamed distribution that we cannot easily work with. In these cases, MCMC methods are used to <em>sample from</em> the unnamed posterior probability distribution, and statistics are calculated on the samples to determine the mean of the distribution, the median, the 95% credible interval, etc of this unnamed distribution.</p>
<p>MCMC methods construct a Markov chain that tends to stay in states that are of higher probability in the posterior distribution, and tends to avoid states that are of lower probability. The equillibrium distribution of the MCMC will therefore be the posterior distribution, and in the long term the distribution of states that are sampled by that MCMC will correspond to the posterior distribution.</p>
<p>The algorithm that is commonly used to construct MCMCs is called the Metropolis-Hastings algorithm: <a href="https://stephens999.github.io/fiveMinuteStats/MH_intro.html" class="uri">https://stephens999.github.io/fiveMinuteStats/MH_intro.html</a></p>
</div>
<div id="addendum-hidden-markov-models" class="section level2">
<h2>Addendum: Hidden Markov Models</h2>
<p>Markov chains are very useful when we are trying to compute the probability for a sequence of events. However, much of the time we don’t actually observe the sequence of events directly (i.e. they are hidden from us). For example, when we look at a sequence of DNA, we don’t see promoters or enhancers or introns or exons directly. Instead, what we see is a string of A T C and Gs. When we look at a sentence, we don’t see parts of speech. Instead, we see words and can infer their parts of speech based on the sequence we observe them in. Hidden markov models (HMM) are an excellent way to model these types of situations, where we are dealing with both hidden and observed states.</p>
<div id="components-of-a-hmm" class="section level3">
<h3>Components of a HMM</h3>
<p>A HMM can be determined partially using the same elements we described for a regular markov chain, but we need to add on more terms in order to fully determine it.</p>
<ol style="list-style-type: decimal">
<li><p>A transition probability matrix (P) that defines the transition probabilities between each pair of <strong>hidden</strong> states i and j (<span class="math inline">\(P_{ij} = P(S_t = j | S_{t-1}=i)\)</span>).</p></li>
<li><p>An initial probability distribution vector (<span class="math inline">\(\pi\)</span>) containing values for <span class="math inline">\(P(\pi_0 = i)\)</span> for each state i.</p></li>
<li><p>A set of <em>emission probabilities</em>, which express the probability of an observed state (<span class="math inline">\(X_t\)</span>) given</p></li>
</ol>
<p>We can see a graphical depiction of a HMM here:</p>
<p><a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs13253-017-0283-8/MediaObjects/13253_2017_283_Fig1_HTML.gif" class="uri">https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs13253-017-0283-8/MediaObjects/13253_2017_283_Fig1_HTML.gif</a></p>
<p><a href="http://compbio.mit.edu/ChromHMM/" class="uri">http://compbio.mit.edu/ChromHMM/</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1233730/" class="uri">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1233730/</a></p>
<p>Examples of HMMs used in biology abound, and in fact more often than not Hidden Markov chains are a better model of what happens in Biology than a strict Markov chain. Why might this be? <hide>Because Markov chains rely on observed states being exactly mapping to what they are (somewhat like a HMM with a 1:1 mapping between hidden and observed states), any extra interference between “what you see” and “what’s really there” will prevent a Markov chain from accurately modeling the data. Because scientific measurements are often noisy (and biology is itself very noisy), we rarely ever observe hidden states in nature.</hide></p>
<p>There are three so called “problems” to solve when working with HMMs in order to determine the parameters of a HMM that best fit some observed data:</p>
<ol style="list-style-type: decimal">
<li>The Evaluation Problem Given an HMM and a sequence of observations, what is the probability that the observations are generated by the model (likelihood for the model)?</li>
<li>The Decoding Problem Given an HMM and a sequence of observations, what is the most likely <em>state</em> sequence in the model that produced the observations (What is the state sequence)?</li>
<li>The Learning Problem Given an HMM and a sequence of observations, how should we adjust the model parameters in order to maximize the probability that the observations are generated by the model (What HMM best fits the observations)?</li>
</ol>
</div>
</div>
<div id="exercises" class="section level2">
<h2>Exercises:</h2>
<p>Use R and matrix multiplication to solve these problems From Sheldon Ross’s <em>Introduction to Probability Models</em>, 11th ed.:</p>
<ol style="list-style-type: decimal">
<li><p>Coin 1 comes up heads with probability 0.6 and coin 2 with probability 0.5. A coin is continually flipped until it comes up tails, at which time that coin is put aside and we start flipping the other one. If we start the process with coin 1 what is the probability that coin 2 is used on the fifth flip? <hide> 4/9</hide></p></li>
<li><p>Suppose that coin 1 has probability 0.7 of coming up heads, and coin 2 has probability 0.6 of coming up heads. If the coin flipped today comes up heads, then we select coin 1 to flip tomorrow, and if it comes up tails, then we select coin 2 to flip tomorrow. If the coin initially flipped is equally likely to be coin 1 or coin 2, then what is the probability that the coin flipped on the third day after the initial flip is coin 1? Suppose that the coin flipped on Monday comes up heads. What is the probability that the coin flipped on Friday of the same week also comes up heads?</p></li>
</ol>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.3 (2020-02-29)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Catalina 10.15.5

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] expm_0.999-4    Matrix_1.2-18   workflowr_1.5.0

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6    lattice_0.20-38 rprojroot_1.3-2 digest_0.6.25  
 [5] later_1.0.0     grid_3.6.3      R6_2.4.1        backports_1.1.6
 [9] git2r_0.26.1    magrittr_1.5    evaluate_0.14   stringi_1.4.5  
[13] rlang_0.4.5     fs_1.3.1        promises_1.1.0  whisker_0.4    
[17] rmarkdown_1.18  tools_3.6.3     stringr_1.4.0   glue_1.4.0     
[21] httpuv_1.5.2    xfun_0.12       yaml_2.2.1      compiler_3.6.3 
[25] htmltools_0.4.0 knitr_1.26     </code></pre>
</div>
</div>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
