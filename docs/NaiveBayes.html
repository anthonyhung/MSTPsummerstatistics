<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Anthony Hung" />

<meta name="date" content="2019-08-06" />

<title>Naive Bayes Classifier</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ISTP Summer JC: Statistical Theory & Methods</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/anthonyhung/MSTPsummerstatistics">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<!-- Add a small amount of space between sections. -->
  <style type="text/css">
    div.section {
      padding-top: 12px;
    }
  </style>

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Naive Bayes Classifier</h1>
<h4 class="author">Anthony Hung</h4>
<h4 class="date">2019-08-06</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#what-is-machine-learning">What is Machine learning?</a></li>
<li><a href="#what-is-classification">What is classification?</a></li>
<li><a href="#motivating-example-is-this-mushroom-poisonous-or-not">Motivating example: Is this Mushroom poisonous or not?</a></li>
</ul></li>
<li><a href="#review-of-bayes-rule">Review of Bayes rule</a><ul>
<li><a href="#derivation-of-bayes-rule">Derivation of Bayes rule</a></li>
<li><a href="#applying-bayes-theorem-example-of-screening-test">Applying Bayes theorem: Example of screening test</a></li>
<li><a href="#exercise">Exercise:</a></li>
<li><a href="#components-of-bayes-rule">Components of Bayes rule</a></li>
</ul></li>
<li><a href="#exercise-naive-bayes-classifier-to-classify-mushrooms">Exercise: Naive Bayes classifier to classify mushrooms</a><ul>
<li><a href="#training-a-naive-bayes-algorithm-using-training-data">Training a Naive Bayes algorithm using training data</a><ul>
<li><a href="#estimating-prior-probabilities-from-training-data">1. Estimating Prior probabilities from training data</a></li>
<li><a href="#estimating-likelihoods-from-training-data">2. Estimating likelihoods from training data</a></li>
<li><a href="#putting-it-all-together-computing-a-posteriori-probabilities-using-bayes-rule">3. Putting it all together: computing a posteriori probabilities using Bayes rule</a></li>
</ul></li>
</ul></li>
<li><a href="#additional-notes-relevant-to-training-machine-learning-algorithms.">Additional notes relevant to training machine learning algorithms.</a><ul>
<li><a href="#another-issue-the-issue-of-overfitting">Another Issue: The issue of overfitting</a><ul>
<li><a href="#one-way-to-assess-overfitting-splitting-data-into-training-vs-test-data-sets-i.e.-the-hold-out-method">One way to assess overfitting: Splitting data into training vs test data sets (i.e. the “Hold out” method)</a></li>
<li><a href="#sidebar-evaluating-model-performance">Sidebar: Evaluating model performance</a></li>
<li><a href="#an-additional-problem-unlucky-splits">An additional problem: Unlucky splits</a></li>
<li><a href="#cross-validation-to-avoid-unlucky-splits">Cross-validation to avoid unlucky splits</a></li>
</ul></li>
</ul></li>
<li><a href="#naive-bayes-classifier-in-r">Naive Bayes classifier in R</a></li>
</ul>
</div>

<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2020-05-10
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>MSTPsummerstatistics/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.5.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20180927code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20180927)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20180927code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20180927)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomanthonyhungMSTPsummerstatisticstree6d7daf110e6bc483f1dce5235850d82642bacd81targetblank6d7daf1a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/anthonyhung/MSTPsummerstatistics/tree/6d7daf110e6bc483f1dce5235850d82642bacd81" target="_blank">6d7daf1</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomanthonyhungMSTPsummerstatisticstree6d7daf110e6bc483f1dce5235850d82642bacd81targetblank6d7daf1a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .RData
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.RData
    Ignored:    analysis/.Rhistory
    Ignored:    data/.DS_Store

Unstaged changes:
    Modified:   analysis/NaiveBayes.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/2114e6c9aebfa316aab6c7a2676ebdce1bc08ef5/docs/NaiveBayes.html" target="_blank">2114e6c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/29c91df7cfe6c689a286531fc31948746f830894/docs/NaiveBayes.html" target="_blank">29c91df</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-10
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/8e5d9b0fc41ba7f478a3572009ea4738dba0bf61/analysis/NaiveBayes.Rmd" target="_blank">8e5d9b0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
add exercises
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ab1bee8db3437619acc9c8fbf3bbe6101a260888/analysis/NaiveBayes.Rmd" target="_blank">ab1bee8</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
add description of PR vs ROC
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/ab1bee8db3437619acc9c8fbf3bbe6101a260888/docs/NaiveBayes.html" target="_blank">ab1bee8</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
add description of PR vs ROC
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/analysis/NaiveBayes.Rmd" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
add ROC
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/NaiveBayes.html" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
<td>
add ROC
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/e18c369e3fcbb64ccf95c695d84510a1fcb0acac/docs/NaiveBayes.html" target="_blank">e18c369</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-02
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/0e6b6d0fad27510d20b1193d8939bac1d6fc3263/docs/NaiveBayes.html" target="_blank">0e6b6d0</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/NaiveBayes.html" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/4e089357d0e95411d0a6199b2a4d314567d7088a/docs/NaiveBayes.html" target="_blank">4e08935</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-03-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/f15db48dbd6a0ea59883ffe6c16b34a3f5c2f4a2/docs/NaiveBayes.html" target="_blank">f15db48</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-03-30
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/NaiveBayes.html" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/e6a84ffea92f1a6e2aa6cbdf7df6089b81c14d77/analysis/NaiveBayes.Rmd" target="_blank">e6a84ff</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-14
</td>
<td>
correct typos
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/96722bdbe5195cb0e43c78b0bc8de5a17af3db56/docs/NaiveBayes.html" target="_blank">96722bd</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/analysis/NaiveBayes.Rmd" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
<td>
add NaiveBayes
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/anthonyhung/MSTPsummerstatistics/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/NaiveBayes.html" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
<td>
add NaiveBayes
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<style>
hide {
  background-color: #d6d6d6;
  color: #d6d6d6;
}
hide:hover {
  background-color: white;
  color: black;
}
</style>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The Naive Bayes classifiers are a class of supervised machine learning algorithms that use Bayes rule to solve classification problems. Today we will introduce the concept of classification and implement a Naive Bayes classifier to build a classifier to identify poisonous mushrooms.</p>
<div id="what-is-machine-learning" class="section level2">
<h2>What is Machine learning?</h2>
<p>Machine learning is a field that leverages generic algorithms that learn pattterns from data rather than having to write code that specifically instructs the algorithm what patterns to focus on.</p>
</div>
<div id="what-is-classification" class="section level2">
<h2>What is classification?</h2>
<p>Classification is essentially the act of arranging items into categories according to shared characteristics amongst the items in the same category. An example is classifying a banana and apple as fruits and lettuce and spinach as vegetables. In machine learning, classification is typically an example of <em>supervised learning</em>, in which an algorithm learns from a user-supplied gold standard example of data and assigned category labels in order to determine patterns and shared characteristics that define each category. For example, consider this table of data that contains information about individual mushroom samples. The original data comes from UCI’s Machine learning department via kaggle: <a href="https://www.kaggle.com/uciml/mushroom-classification" class="uri">https://www.kaggle.com/uciml/mushroom-classification</a>.</p>
<p>Other broad types of machine learning are depicted here: <a href="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2019/08/Types-of-Machine-Learning-algorithms.jpg" class="uri">https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2019/08/Types-of-Machine-Learning-algorithms.jpg</a></p>
</div>
<div id="motivating-example-is-this-mushroom-poisonous-or-not" class="section level2">
<h2>Motivating example: Is this Mushroom poisonous or not?</h2>
<pre class="r"><code>mush_data &lt;- read.csv(&quot;data/mushrooms.csv&quot;)
mush_data[1:6,1:6]</code></pre>
<pre><code>  class cap.shape cap.surface cap.color bruises odor
1     p         x           s         n       t    p
2     e         x           s         y       t    a
3     e         b           s         w       t    l
4     p         x           y         w       t    p
5     e         x           s         g       f    n
6     e         x           y         y       t    a</code></pre>
<p>We can break down the above table into two different elements. The first, containing all the columns except for the first one, is also known as the “feature matrix”. This matrix contains descriptions of each of the features that describe each of the individual mushrooms (i.e. mushroom 1 has a cap shape that can be described as conveX, a cap surface that is Smooth, a cap color of browN, has bruises, and a Pungent odor). The second element is the first column, also known as the “response vector”. The response vector contains the class of each of the mushrooms (the response variable in our case).</p>
<p>Notice that the response variable is a categorical variable that can take on one of two values: {e=edible, p=poisonous}. In classification problems, the y variable is always categorical. The analogous situation for when you have a <em>continouous</em> response variable is regression, which will be covered in a later lecture.</p>
<p>Using this labeled dataset, we can teach a classification algorithm how to predict if a new mushroom is poisonous or not, given we have information about the other features of that mushroom. In order to do this, the algorithm must search for patterns amongst the other features that are shared between poisonous mushrooms and distinguish these mushrooms from edible ones. One way to do this is through using a Naive bayes classifier.</p>
<p>As a side note, a third task that is often performed with machine learning is <em>clustering</em>, in which clusters are learned from the input data themselves rather than being specified by the user. This is a case of <em>unsupervised learning</em>, meaning the algorithm is not supplied with gold standard examples of what each cluster looks like but rather defines them on its own.</p>
</div>
</div>
<div id="review-of-bayes-rule" class="section level1">
<h1>Review of Bayes rule</h1>
<p>Before we jump into the applied example, we must first review the components of Bayes rule. Bayes rule is a result that comes from probability and describes the relationship between conditional probabilities.</p>
<p>Let us define A and B as two separate types of events. P(A|B), or “the probability of A given B” denotes the conditional probability of A occurring if we know that B has occurred. Likewise, P(B|A) denotes “the probability of B given A”. Bayes theorem relates P(A|B) and P(B|A) in a deceptively simple equation.</p>
<div id="derivation-of-bayes-rule" class="section level2">
<h2>Derivation of Bayes rule</h2>
<p><a href="https://oracleaide.files.wordpress.com/2012/12/ovals_pink_and_blue1.png" class="uri">https://oracleaide.files.wordpress.com/2012/12/ovals_pink_and_blue1.png</a></p>
<p>From our definition of conditional probability, we know that P(A|B) can be defined as the probability that A occurs given that B has occured. This can be written mathematically as:</p>
<p><span class="math display">\[P(A|B) = \frac{P(A \cap B )}{P(B)}\]</span></p>
<p>Here, <span class="math inline">\(\cap\)</span> denotes the intersection between A and B (i.e. “A AND B occur together”). To calculate the probability of A conditional on B, we first need to find the probability that B has occured. Then, we need to figure out out of the situations where B has occured, how often does A also occur?</p>
<p>In a similar way, we can write P(B|A) mathematically:</p>
<p><span class="math display">\[P(B|A) = \frac{P(B \cap A )}{P(A)}\]</span></p>
<p>Since <span class="math inline">\(P(B \cap A )=P(A \cap B)\)</span> (does this make sense?), we can combine the two equations:</p>
<p><span class="math display">\[P(A|B)P(B) = P(B \cap A ) = P(B|A)P(A)\]</span></p>
<p>If we divide both sides by P(B):</p>
<p><span class="math display">\[P(A|B) = \frac{P(B|A )P(A)}{P(B)}\]</span></p>
<p>This is Bayes theorem! Notice that using this equation, we can connect the two conditional probabilities. Oftentimes, knowing this relationship is extremely useful because we will know P(B|A) but want to compute P(A|B). Let’s explore an example.</p>
</div>
<div id="applying-bayes-theorem-example-of-screening-test" class="section level2">
<h2>Applying Bayes theorem: Example of screening test</h2>
<p>Let us assume that a patient named John goes to a see a doctor to undergo a screening test for an infectious disease. The test that is performed has been previously researched, and it is known to have a 99% reliability when administered to patients like John. In other words, 99% of sick people test positive in the test and 99% of healthy people test negative. The doctor has prior knowledge that 1% of people in general will have the disease in question. If the patient tests positive, what are the chances that he is sick?</p>
<p><hide>50%</hide></p>
</div>
<div id="exercise" class="section level2">
<h2>Exercise:</h2>
<p>In a particular pain clinic, 10% of patients are prescribed narcotic pain killers. Overall, five percent of the clinic’s patients are addicted to narcotics (including pain killers and illegal substances). Out of all the people prescribed pain pills, 8% are addicts. If a patient is an addict, what is the probability that they will be prescribed pain pills? <hide>16%</hide></p>
</div>
<div id="components-of-bayes-rule" class="section level2">
<h2>Components of Bayes rule</h2>
<p><span class="math display">\[P(A|B) = \frac{P(B|A )P(A)}{P(B)}\]</span></p>
<p>If we define B to be our observed data (i.e. features of a mushroom), then Bayes theorem becomes:</p>
<p><span class="math display">\[P(A|Data) = \frac{P(Data|A )P(A)}{P(Data)}\]</span></p>
<p>Notice the <span class="math inline">\(P(Data|A)\)</span> term is something we’ve talked about earlier, the likelihood. “The likelihood for a model is the probability of the data under the model.” With that in mind, we can now attach names to each of the terms in the equation.</p>
<ul>
<li><p>P(A|Data) is known as the a posteriori probability, or the probability of a model A given some observations.</p></li>
<li><p>P(Data|A) is known as the likelihood.</p></li>
<li><p>P(A) is known as the prior probability, or the probability of A before we have the observations.</p></li>
<li><p>P(Data) is the prior probability that the data themselves are true.</p></li>
</ul>
<p>Let us say we have two possible models <span class="math inline">\(A_p\)</span> and <span class="math inline">\(A_e\)</span> that could have generated our data that we would like to pick between.</p>
<p><span class="math display">\[P(A_p|Data) = \frac{P(Data|A_p )P(A_p)}{P(Data)}\]</span></p>
<p>and</p>
<p><span class="math display">\[P(A_e|Data) = \frac{P(Data|A_e )P(A_e)}{P(Data)}\]</span></p>
<p>If we would like to compare the probability that a certain set of data (or features of a mushroom) came from model <span class="math inline">\(A_e\)</span> with the probability that the data came from model <span class="math inline">\(A_p\)</span>, we can simply compare their a posteriori probabilities <span class="math inline">\(P(A_e|Data)\)</span> and <span class="math inline">\(P(A_p|Data)\)</span>. Additionally, we can notice that both of these a posteriori probabilities contain the same denominators, which means that the denominator can be ignored when comparing between them to see which is larger. Therefore, we can compare <span class="math inline">\(P(Data|A_e)P(A_e)\)</span> and <span class="math inline">\(P(Data|A_p)P(A_p)\)</span> to determine the model that has the higher probability of generating the observed data. Being able to ignore the denominator when using Bayes rule to compare between two (or more) models is an extremely convenient trick and simplifies things mathematically a great deal.</p>
<p>A Naive Bayes Classifier uses data that is fed into it to estimate prior probabilities and likelihoods to be used in Bayes rule. The classifier then uses Bayes rule to compute the posterior probability that a new observation belongs to each possible defined class given its other features. It then assigns the observation to the class that has the largest posterior probability (“Maximum A Posteriori Probability”, or MAP).</p>
</div>
</div>
<div id="exercise-naive-bayes-classifier-to-classify-mushrooms" class="section level1">
<h1>Exercise: Naive Bayes classifier to classify mushrooms</h1>
<p>The reason why this is called a “Naive” Bayes classifier is that this algorithm assumes that each feature in the feature matrix is independent of all others and equal to all others in weight. For example, in our mushroom example a Naive Bayes classifier assumes that the cap shape of a mushroom does not depend on the cap color. Also, each feature carries equal weight in determining which class a row belongs to: there are no features that are irrelevant and each features contributes equally to the classification. Even though these conditions are almost never completely true in practice, the classifier still works very well in situations where these assumptions are violated.</p>
<p>Let’s walk through conceptually what the Naive Bayes algorithm does, and then look at how R can help perform each step.</p>
<div id="training-a-naive-bayes-algorithm-using-training-data" class="section level2">
<h2>Training a Naive Bayes algorithm using training data</h2>
<p>As mentioned previously, training of a Naive Bayes algorithm essentially boils down to using training data to estimate values for prior probabilities (<span class="math inline">\(P(A_p)\)</span> and <span class="math inline">\(P(A_e)\)</span>) and likelihoods (<span class="math inline">\(P(Data|A_p)\)</span> and <span class="math inline">\(P(Data|A_e)\)</span>) to be inputted into Bayes rule.</p>
<div id="estimating-prior-probabilities-from-training-data" class="section level3">
<h3>1. Estimating Prior probabilities from training data</h3>
<p>Question: What would be a good way to come up with a prior probability for a mushroom being poisonous if you have access to a labeled training dataset? Recall that a prior probability is the probability of a certain model <em>before</em> you have access to any data.</p>
<p><hide>Simply calculate the proportion of observations in the training data that belong that are poisonous. Alternatively, one could also argue that we treat the prior probabilities as 1/2 and 1/2, treating each class as equally likely.</hide></p>
<p>Pretty straightforward.</p>
</div>
<div id="estimating-likelihoods-from-training-data" class="section level3">
<h3>2. Estimating likelihoods from training data</h3>
<p>Now, we need to calculate the other missing part of our Bayes rule equation: the likelihoods. A likelihood is similar to, but not equivalent to, a probability.</p>
<div id="likelihood-vs-probability" class="section level4">
<h4>Likelihood vs probability</h4>
<div id="probability" class="section level5">
<h5>Probability</h5>
<p>Recall from our previous class on probability distributions that the definition of probability can be visualized as the area under the curve of a probability distribution. For example, let’s say that we have a fair coin (P(heads) = 0.5) and we flip it 30 times:</p>
<pre class="r"><code>library(ggplot2)
library(cowplot)</code></pre>
<pre><code>
********************************************************</code></pre>
<pre><code>Note: As of version 1.0.0, cowplot does not change the</code></pre>
<pre><code>  default ggplot2 theme anymore. To recover the previous</code></pre>
<pre><code>  behavior, execute:
  theme_set(theme_cowplot())</code></pre>
<pre><code>********************************************************</code></pre>
<pre class="r"><code>library(grid)

x1  &lt;- 5:25
df &lt;- data.frame(x = x1, y = dbinom(x1, 30, 0.5))

ggplot(df, aes(x = x, y = y)) +
  geom_bar(stat = &quot;identity&quot;, col = &quot;red&quot;, fill = c(&quot;white&quot;)) +
  scale_y_continuous(expand = c(0.01, 0)) + xlab(&quot;number of heads&quot;) + ylab(&quot;Density&quot;)</code></pre>
<p><img src="figure/NaiveBayes.Rmd/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-2-1">
Past versions of unnamed-chunk-2-1.png
</button>
</p>
<div id="fig-unnamed-chunk-2-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/figure/NaiveBayes.Rmd/unnamed-chunk-2-1.png" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/figure/NaiveBayes.Rmd/unnamed-chunk-2-1.png" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/figure/NaiveBayes.Rmd/unnamed-chunk-2-1.png" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>If we would like to find the probability that we would get more than 20 heads in 30 flips, we could calculate the area represented by bars that are greater than 18 on the x axis:</p>
<pre class="r"><code>ggplot(df, aes(x = x, y = y)) +
  geom_bar(stat = &quot;identity&quot;, col = &quot;red&quot;, fill = c(rep(&quot;white&quot;, 14), rep(&quot;red&quot;, 7))) +
  scale_y_continuous(expand = c(0.01, 0)) + xlab(&quot;number of heads&quot;) + ylab(&quot;Density&quot;)</code></pre>
<p><img src="figure/NaiveBayes.Rmd/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-3-1">
Past versions of unnamed-chunk-3-1.png
</button>
</p>
<div id="fig-unnamed-chunk-3-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/figure/NaiveBayes.Rmd/unnamed-chunk-3-1.png" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/figure/NaiveBayes.Rmd/unnamed-chunk-3-1.png" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/figure/NaiveBayes.Rmd/unnamed-chunk-3-1.png" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Similarly, we could calculate the probability that we get between 9 and 13 heads:</p>
<pre class="r"><code>ggplot(df, aes(x = x, y = y)) +
  geom_bar(stat = &quot;identity&quot;, col = &quot;red&quot;, fill = c(rep(&quot;white&quot;, 5), rep(&quot;red&quot;, 4), rep(&quot;white&quot;, 12))) +
  scale_y_continuous(expand = c(0.01, 0)) + xlab(&quot;number of heads&quot;) + ylab(&quot;Density&quot;)</code></pre>
<p><img src="figure/NaiveBayes.Rmd/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-4-1">
Past versions of unnamed-chunk-4-1.png
</button>
</p>
<div id="fig-unnamed-chunk-4-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/figure/NaiveBayes.Rmd/unnamed-chunk-4-1.png" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/figure/NaiveBayes.Rmd/unnamed-chunk-4-1.png" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/figure/NaiveBayes.Rmd/unnamed-chunk-4-1.png" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>In each case, notice that the shape of the distribution does not change. The only thing that changes is the area that we shade in. In mathematical terms, in the first case we are calculating:</p>
<p><span class="math display">\[P(num\_heads &gt; 20 | Binom(n=30, p=0.5))\]</span></p>
<p>and in the second:</p>
<p><span class="math display">\[P(9&lt; num\_heads &lt; 13 | Binom(n=30, p=0.5))\]</span></p>
<p>What is changing is the left side of the | . The shape of the distribution stays the same. When we discuss probabilities, we are talking about the areas under a <strong>fixed distribution (model)</strong>.</p>
</div>
<div id="likelihood" class="section level5">
<h5>Likelihood</h5>
<p>So what about likelihood? Before we look at it graphically, let’s define what we mean by the term. “The likelihood for a model is the probability of the data under the model.” Mathematically,</p>
<p><span class="math display">\[L(Model;Data) = P(Data|Model)\]</span></p>
<p>This may look the same as what we did before, but in this case our <strong>data are fixed</strong>, not the distribution. Instead of asking, “If I keep my distribution constant, what is the probability of observing something?” with likelihood we are asking “Given that I have collected some data, how well does a certain distribution fit the data?”</p>
<p>Let’s assume the same situation we did for probability with the coin. In this case, we do not know if the coin is actually fair (P(heads = 0.5), or if it is rigged (e.g. P(heads = 0.6). We flip the coin 30 times and observe 20 heads.</p>
<p>What is the likelihood for our <strong>fair model</strong> (<span class="math inline">\(Binom(n=30, p=0.5)\)</span>) given that we observe these data? In other words, how well does the model as paramterized fit our observations?</p>
<p><span class="math display">\[L(Model;Data) = P(num\_heads = 20|Binom(n=30, p=0.5))\]</span></p>
<p>Let’s look at this graphically.</p>
<pre class="r"><code>ggplot(df, aes(x = x, y = y)) +
  geom_bar(stat = &quot;identity&quot;, col = &quot;red&quot;, fill = c(rep(&quot;white&quot;, 15), rep(&quot;red&quot;, 1), rep(&quot;white&quot;, 5))) +
  scale_y_continuous(expand = c(0.01, 0)) + xlab(&quot;number of heads&quot;) + ylab(&quot;Density&quot;)</code></pre>
<p><img src="figure/NaiveBayes.Rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-5-1">
Past versions of unnamed-chunk-5-1.png
</button>
</p>
<div id="fig-unnamed-chunk-5-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/figure/NaiveBayes.Rmd/unnamed-chunk-5-1.png" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/figure/NaiveBayes.Rmd/unnamed-chunk-5-1.png" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/figure/NaiveBayes.Rmd/unnamed-chunk-5-1.png" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We can also compute the exact probability using the “dbinom” function in R.</p>
<pre class="r"><code>dbinom(x = 20, size = 30, prob = 0.5)</code></pre>
<pre><code>[1] 0.0279816</code></pre>
<p>Okay. How well does our data fit a <strong>rigged coin</strong> model, where the P(heads = 0.6)? What is the likelihood for the rigged coin model given our data?</p>
<p><span class="math display">\[L(Model;Data) = P(num\_heads = 25|Binom(n=30, p=0.6))\]</span></p>
<p>Let’s look at this graphically.</p>
<pre class="r"><code>x1  &lt;- 5:25
df_rigged &lt;- data.frame(x = x1, y = dbinom(x1, 30, 0.6))

ggplot(df_rigged, aes(x = x, y = y)) +
  geom_bar(stat = &quot;identity&quot;, col = &quot;red&quot;, fill = c(rep(&quot;white&quot;, 15), rep(&quot;red&quot;, 1), rep(&quot;white&quot;, 5))) +
  scale_y_continuous(expand = c(0.01, 0)) + xlab(&quot;number of heads&quot;) + ylab(&quot;Density&quot;)</code></pre>
<p><img src="figure/NaiveBayes.Rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-7-1">
Past versions of unnamed-chunk-7-1.png
</button>
</p>
<div id="fig-unnamed-chunk-7-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/5cbe42ce67e5f188c7e88ac65574f4e6318920ae/docs/figure/NaiveBayes.Rmd/unnamed-chunk-7-1.png" target="_blank">5cbe42c</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-04-23
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/310d040edca8fa7dc53f12dd0ba799f63e4259a4/docs/figure/NaiveBayes.Rmd/unnamed-chunk-7-1.png" target="_blank">310d040</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-02-20
</td>
</tr>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/7c276548c891e06bd0a8e32d0e41670457e4c30f/docs/figure/NaiveBayes.Rmd/unnamed-chunk-7-1.png" target="_blank">7c27654</a>
</td>
<td>
Anthony Hung
</td>
<td>
2019-08-07
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We can also compute the exact probability using the “dbinom” function in R.</p>
<pre class="r"><code>dbinom(x = 20, size = 30, prob = 0.6)</code></pre>
<pre><code>[1] 0.1151854</code></pre>
<p>It looks like the likelihood for the rigged coin model is higher!</p>
</div>
</div>
<div id="determining-likelihood-equations" class="section level4">
<h4>Determining likelihood equations</h4>
<p>Now, let’s approach computing likelihoods for our mushroom example. The first thing we need to do is choose an appropriate distribution to model our data. Given that each of our features is a categorical variable that has either 2 or more than 2 levels, what is the best distribution to choose for the expression <span class="math inline">\(P(Data|A_p)\)</span> for each individual feature (e.g. cap shape)?</p>
<p><hide>For the features that are categorical variables with 2 levels, a Bernoulli likelihood is most appropriate (this is also equivalent to a binomial distribution with only 1 trial). For the features that are categorical variables with more than 2 levels, a multinomial likelihood is appropriate (or more specifically, the categorical distribution).</hide></p>
<p>The multinomial distribution is a generalization of the binomial to cases where the number of categories is greater than 2. Recall that a binomial distribution describes the probability of observing k successes in n trials, with the result of each trial being either a success or a failure (2 possible categories of results). The multinomial distribution expands the number of possible categories of results to beyond 2. In other words, while you can use the binomial distribution to model the probability of observing a number of heads in n coin filps, you can use the multinomial distribution to model the probability of landing on any one of the sides of a 6-sided dice a certain number of times after n throws of the dice.</p>
<p>(Also, for distributions, categorical : multinomial :: bernoulli : binomial)</p>
<p>We can get the PMFs for the bernoulli and multinomial distributions from memory or wikipedia: <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" class="uri">https://en.wikipedia.org/wiki/Bernoulli_distribution</a>, <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" class="uri">https://en.wikipedia.org/wiki/Multinomial_distribution</a>. These are our likelihood equations.</p>
</div>
<div id="estimating-likelihoods-from-training-data-1" class="section level4">
<h4>Estimating likelihoods from training data</h4>
<p>Now that we have determined our likelihood equations, we can move on to estimating the parameters that will fit into these equations from our training data.</p>
<p>In both cases (bernoulli and multinomial), the number of trials n will be 1. Why is this? <hide>Each mushroom will only have one value for each feature. For example, a mushroom cannot have a bell shaped and conical shaped cap at the same time, and cannot have a doubly-bell shaped cap.</hide></p>
<p>All that is left to estimate, therefore, are the event probabilities p for the bernoulli or <span class="math inline">\(p_1, p_2, p_3, ... p_k\)</span> for the multinomial. What is an intuitve way to estimate these probabilities from our training data? <hide>Much like what we did above for our prior probabiliites, we can simply find the proportion of mushrooms that are classified as poisonous in our training data that have bell shaped caps, conical shaped caps, etc. and do the same for the mushrooms that are classified as edible. These probabilities should add up to 1 within each feature within each class of mushroom. If you look hard enough at the PMFs for either the bernoulli or multinomial distributions where n = 1, you’ll be able to see that it’s actually very very easy to compute likelihoods for each individual feature.</hide></p>
</div>
</div>
<div id="putting-it-all-together-computing-a-posteriori-probabilities-using-bayes-rule" class="section level3">
<h3>3. Putting it all together: computing a posteriori probabilities using Bayes rule</h3>
<p>Cool, now that we have all the pieces, we can use Bayes rule to calculate our posterior probabilities. Recall that since the denominators will always be the same across categories when using Bayes rule, we can omit them and instead use a simplified version of the equation:</p>
<p><span class="math display">\[Posterior \propto Prior * Likelihood\]</span></p>
<p>Recall also that the <em>Naive</em> in Naive Bayes means we are assuming that each of our features is independent. This means that to calculate the joint probabilities across all of features for an individual mushroom, we can simply take the product of the likelihoods for each individual feature (multiply many multinomial/bernoulli likelihoods together).</p>
<p><span class="math display">\[Posterior_{edible} \propto Prior_{edible} * Likelihood_{cap.shape\_edible} * Likelihood_{cap.surface\_edible} * Likelihood_{cap.color\_edible} * ... * Likelihood_{habitat\_edible}\]</span></p>
<p>or</p>
<p><span class="math display">\[P(A_{edible}|Data) \propto P(A_{edible}) * P(Data_{cap.shape}|A_{edible}) * P(Data_{cap.surface}|A_{edible}) * P(Data_{cap.color}|A_{edible}) * ... * P(Data_{habitat}|A_{edible})\]</span></p>
<p>Using R, we can easily obtain the numbers needed to estimate the prior probabilties and the event probabilities from our mushroom data using a few commands. We will not walk through individually calculating all the likelihoods because there are automated packages to do all the steps conveniently in R/other programming languages.</p>
<pre class="r"><code>#prior probabilties:
summary(mush_data)</code></pre>
<pre><code> class    cap.shape cap.surface   cap.color    bruises       odor     
 e:4208   b: 452    f:2320      n      :2284   f:4748   n      :3528  
 p:3916   c:   4    g:   4      g      :1840   t:3376   f      :2160  
          f:3152    s:2556      e      :1500            s      : 576  
          k: 828    y:3244      y      :1072            y      : 576  
          s:  32                w      :1040            a      : 400  
          x:3656                b      : 168            l      : 400  
                                (Other): 220            (Other): 484  
 gill.attachment gill.spacing gill.size   gill.color   stalk.shape stalk.root
 a: 210          c:6812       b:5612    b      :1728   e:3516      ?:2480    
 f:7914          w:1312       n:2512    p      :1492   t:4608      b:3776    
                                        w      :1202               c: 556    
                                        n      :1048               e:1120    
                                        g      : 752               r: 192    
                                        h      : 732                         
                                        (Other):1170                         
 stalk.surface.above.ring stalk.surface.below.ring stalk.color.above.ring
 f: 552                   f: 600                   w      :4464          
 k:2372                   k:2304                   p      :1872          
 s:5176                   s:4936                   g      : 576          
 y:  24                   y: 284                   n      : 448          
                                                   b      : 432          
                                                   o      : 192          
                                                   (Other): 140          
 stalk.color.below.ring veil.type veil.color ring.number ring.type
 w      :4384           p:8124    n:  96     n:  36      e:2776   
 p      :1872                     o:  96     o:7488      f:  48   
 g      : 576                     w:7924     t: 600      l:1296   
 n      : 512                     y:   8                 n:  36   
 b      : 432                                            p:3968   
 o      : 192                                                     
 (Other): 156                                                     
 spore.print.color population habitat 
 w      :2388      a: 384     d:3148  
 n      :1968      c: 340     g:2148  
 k      :1872      n: 400     l: 832  
 h      :1632      s:1248     m: 292  
 r      :  72      v:4040     p:1144  
 b      :  48      y:1712     u: 368  
 (Other): 144                 w: 192  </code></pre>
<pre class="r"><code>#subset data into poisonous and edible
poisonous &lt;- mush_data[mush_data$class==&quot;p&quot;,]
edible &lt;- mush_data[mush_data$class==&quot;e&quot;,]

#calculate event probabilities for cap.shape for each class
##poisonous
table(poisonous$cap.shape)</code></pre>
<pre><code>
   b    c    f    k    s    x 
  48    4 1556  600    0 1708 </code></pre>
<pre class="r"><code>##edible
table(edible$cap.shape)</code></pre>
<pre><code>
   b    c    f    k    s    x 
 404    0 1596  228   32 1948 </code></pre>
</div>
</div>
</div>
<div id="additional-notes-relevant-to-training-machine-learning-algorithms." class="section level1">
<h1>Additional notes relevant to training machine learning algorithms.</h1>
<p>Before actually carrying out this algorithm in R on our data, we need to discuss some topics that are relevant to machine learning in general when using data to train and evaluate a model.</p>
<div id="another-issue-the-issue-of-overfitting" class="section level2">
<h2>Another Issue: The issue of overfitting</h2>
<p>If you’ve ever heard anyone talking about machine learning, you’ve probably heard of the term “overfitting.” Overfitting can be summed up by any situation where an algorithm learns from the training data … a bit too well. For example, if there are certain patterns in the data you have collected for your training data that are just flukes due to sampling error and do not accurately represent the actual relationships found in the wild, the algorithm you’ve trained will falsely apply these incorrect patterns to new classification problems, leading to inaccurate results. One way to test if your algorithm has overfit your data is to simply collect more labeled data that were not used to train your algorithm and see how well your trained algorithm performs in correctly classifying the new “test” data.</p>
<div id="one-way-to-assess-overfitting-splitting-data-into-training-vs-test-data-sets-i.e.-the-hold-out-method" class="section level3">
<h3>One way to assess overfitting: Splitting data into training vs test data sets (i.e. the “Hold out” method)</h3>
<p>Of course, oftentimes the easier alternative to going out to collect new data is to just pretend that a subset of the data that is already collected is your “test” data set. By randomly partitioning your data into a “training set” and a “test set,” you can assess your algorithm’s ability to perform on previously unseen data to determine if it has overfit your training data. A common split is 20% test data and 80% training data.</p>
</div>
<div id="sidebar-evaluating-model-performance" class="section level3">
<h3>Sidebar: Evaluating model performance</h3>
<p>Now that you’ve separated your data into a training and test set, how do you know if you’ve got a good model? There are numerous ways to evaluate a classifer model’s accuracy, but the most intuitive is a confusion matrix. To build a confusion matrix, you must first generate predictions on your test data and compare these predictions to your actual labels in your test data. A confusion matrix will look something like this (we can define the positive case as either one of our binary classes if there is no obvious “positive” class):</p>
<p><a href="https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMat" class="uri">https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMat</a></p>
<p>Sensitivity is also known as recall.</p>
<p>However, remember that our Naive Bayes classifer doesn’t exactly return hard classifications, but rather probabilities (we take the additional step of setting a threshold of 0.5 to bin these probabilities into hard classifications.) If we would like a measure of our model performance that reflects this probabilistic nature of our predictions, we can use the Receiver Operating Characteristics curve, or ROC curve. A ROC curve looks like this:</p>
<p><a href="https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png" class="uri">https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png</a> <a href="https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png" class="uri">https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png</a></p>
<p>The curves drawn plot the continuous changes in both the false positive rate (1-specificity) and the true positive rate (sensitivity) as we vary the threshold for what probabilities constitute a positive case from 0 to 1. The larger the area <em>under</em> the curve (AUC), the better the model at accurately picking up on positive cases while avoiding falsely calling negative cases positive. Oftentimes for imbalanced test sets (for example, lottery tickets), it makes sense to plot precision and recall on the axes instead of FPR and recall. This is because precision (TP/(TP + FP)) does not include TN in its equation and therefore may be a more accurate metric. In that case, the curve is no longer called the ROC curve but rather the Precision-Recall curve. For our edible/poisonous mushroom example, is it appropriate to use a ROC curve (i.e. are the positive/negative cases very imbalanced or not?).</p>
<p>In either case, the AUC allows us to compare different models, with generally the models with larger AUC having better performance.</p>
</div>
<div id="an-additional-problem-unlucky-splits" class="section level3">
<h3>An additional problem: Unlucky splits</h3>
<p>Of course, the word “randomly” above may trigger warning bells, since the whole problem we are trying to avoid in the first place is sampling error! Therefore, by randomly partitioning our training and test sets, we run into the potential problem of unlucky splits in which our training set looks nothing like our test set, despite both having come from the same larger group of data. In this case, using our test set to evaluate the ability of our algorithm to perform on previously unseen data would be inaccurate.</p>
</div>
<div id="cross-validation-to-avoid-unlucky-splits" class="section level3">
<h3>Cross-validation to avoid unlucky splits</h3>
<p>In order to avoid the above problem, we can employ cross-validation or ‘k-fold cross-validation’. Cross-validation involves randomly splitting our data into ‘k’ equal-sized groups. In each iteration of the process, one of the groups is used as the test set and the rest are used as the training set. The algorithm is trained on the training set and tested on the test set. Then, in the next iteration selects a different group to be used as the test set and rest are used as the training set. The process is repeated until each unique group has been used as the test set in an iteration. For example, in 5-fold cross-validation, we would split the dataset randomly into 5 groups, and run 5 iterations of training and testing. See the graphical depiction below.</p>
<p><a href="https://miro.medium.com/max/1400/1*rgba1BIOUys7wQcXcL4U5A.png" class="uri">https://miro.medium.com/max/1400/1*rgba1BIOUys7wQcXcL4U5A.png</a></p>
</div>
</div>
</div>
<div id="naive-bayes-classifier-in-r" class="section level1">
<h1>Naive Bayes classifier in R</h1>
<p>Finally, after discussing the theoretical basis behind the classifier and the necessity for training/test sets and cross-validation, we will be able to implement our algorithm with 5-fold cross-validation in R. Since others have written neat programs to automate most of the calculations for us, you will find that the implementation is actually quite simple to carry out.</p>
<pre class="r"><code>#Note: a seed has been set already at the beginning of this document, which allows us to reproducibly recreate the random splits that we perform in this code chunk.

#load two libraries in R that are popular for implementing machine learning algorithms
library(e1071)
library(caret)</code></pre>
<pre><code>Loading required package: lattice</code></pre>
<pre class="r"><code>library(pROC) #for getting AUC</code></pre>
<pre><code>Type &#39;citation(&quot;pROC&quot;)&#39; for a citation.</code></pre>
<pre><code>
Attaching package: &#39;pROC&#39;</code></pre>
<pre><code>The following objects are masked from &#39;package:stats&#39;:

    cov, smooth, var</code></pre>
<pre class="r"><code>#randomly subset our data into 5 groups (folds_i is a vector that contains the indices of observations included in each group)
n_folds &lt;- 5
folds_i &lt;- sample(rep(1:n_folds, length.out = nrow(mush_data)))
table(folds_i)</code></pre>
<pre><code>folds_i
   1    2    3    4    5 
1625 1625 1625 1625 1624 </code></pre>
<pre class="r"><code>#iterate through training and testing a naiveBayes classifier for all 5 cross-validation folds and print the results
for(k in 1:n_folds){
  #select which group is our test data and define our training/testing data
  test_i &lt;- which(folds_i == k)
  train_data &lt;- mush_data[-test_i, ]
  test_data &lt;- mush_data[test_i, ]

  #train classifier
  classifier_nb &lt;- naiveBayes(train_data[,-1], train_data$class)

  #use classifier to predict classes of test data
  nb_pred_probabilities &lt;- predict(classifier_nb, newdata = test_data, type = &quot;raw&quot;)

  nb_pred_classes &lt;- predict(classifier_nb, newdata = test_data, type = &quot;class&quot;)

  #assess the accuracy of the classifier on the test data using a confusion matrix
  print(confusionMatrix(nb_pred_classes,test_data$class))

  #assess the accuracy of the classifier on the test data using a ROC (function defined above)
  ROC &lt;- roc(predictor=nb_pred_probabilities[,1],
                 response=test_data$class)
  print(ROC$auc)
  plot(ROC)
}</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 836  91
         p   2 696
                                          
               Accuracy : 0.9428          
                 95% CI : (0.9303, 0.9536)
    No Information Rate : 0.5157          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.885           
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9976          
            Specificity : 0.8844          
         Pos Pred Value : 0.9018          
         Neg Pred Value : 0.9971          
             Prevalence : 0.5157          
         Detection Rate : 0.5145          
   Detection Prevalence : 0.5705          
      Balanced Accuracy : 0.9410          
                                          
       &#39;Positive&#39; Class : e               
                                          </code></pre>
<pre><code>Setting levels: control = e, case = p</code></pre>
<pre><code>Setting direction: controls &gt; cases</code></pre>
<pre><code>Area under the curve: 0.997</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 847 100
         p   4 674
                                         
               Accuracy : 0.936          
                 95% CI : (0.923, 0.9474)
    No Information Rate : 0.5237         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
                                         
                  Kappa : 0.871          
                                         
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16      
                                         
            Sensitivity : 0.9953         
            Specificity : 0.8708         
         Pos Pred Value : 0.8944         
         Neg Pred Value : 0.9941         
             Prevalence : 0.5237         
         Detection Rate : 0.5212         
   Detection Prevalence : 0.5828         
      Balanced Accuracy : 0.9331         
                                         
       &#39;Positive&#39; Class : e              
                                         </code></pre>
<pre><code>Setting levels: control = e, case = p
Setting direction: controls &gt; cases</code></pre>
<p><img src="figure/NaiveBayes.Rmd/NB%20in%20R-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-no-spaces-NB-in-R-1">
Past versions of “NB in R-1.png”
</button>
</p>
<div id="fig-no-spaces-NB-in-R-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/figure/NaiveBayes.Rmd/NB in R-1.png" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre><code>Area under the curve: 0.995</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 831  97
         p  10 687
                                         
               Accuracy : 0.9342         
                 95% CI : (0.921, 0.9457)
    No Information Rate : 0.5175         
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
                                         
                  Kappa : 0.8676         
                                         
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16      
                                         
            Sensitivity : 0.9881         
            Specificity : 0.8763         
         Pos Pred Value : 0.8955         
         Neg Pred Value : 0.9857         
             Prevalence : 0.5175         
         Detection Rate : 0.5114         
   Detection Prevalence : 0.5711         
      Balanced Accuracy : 0.9322         
                                         
       &#39;Positive&#39; Class : e              
                                         </code></pre>
<pre><code>Setting levels: control = e, case = p
Setting direction: controls &gt; cases</code></pre>
<p><img src="figure/NaiveBayes.Rmd/NB%20in%20R-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-no-spaces-NB-in-R-2">
Past versions of “NB in R-2.png”
</button>
</p>
<div id="fig-no-spaces-NB-in-R-2" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/figure/NaiveBayes.Rmd/NB in R-2.png" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre><code>Area under the curve: 0.9939</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 856  90
         p   7 672
                                          
               Accuracy : 0.9403          
                 95% CI : (0.9277, 0.9513)
    No Information Rate : 0.5311          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.8794          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9919          
            Specificity : 0.8819          
         Pos Pred Value : 0.9049          
         Neg Pred Value : 0.9897          
             Prevalence : 0.5311          
         Detection Rate : 0.5268          
   Detection Prevalence : 0.5822          
      Balanced Accuracy : 0.9369          
                                          
       &#39;Positive&#39; Class : e               
                                          </code></pre>
<pre><code>Setting levels: control = e, case = p
Setting direction: controls &gt; cases</code></pre>
<p><img src="figure/NaiveBayes.Rmd/NB%20in%20R-3.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-no-spaces-NB-in-R-3">
Past versions of “NB in R-3.png”
</button>
</p>
<div id="fig-no-spaces-NB-in-R-3" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/figure/NaiveBayes.Rmd/NB in R-3.png" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre><code>Area under the curve: 0.9953</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 810  74
         p   5 735
                                          
               Accuracy : 0.9514          
                 95% CI : (0.9397, 0.9613)
    No Information Rate : 0.5018          
    P-Value [Acc &gt; NIR] : &lt;2e-16          
                                          
                  Kappa : 0.9027          
                                          
 Mcnemar&#39;s Test P-Value : 2e-14           
                                          
            Sensitivity : 0.9939          
            Specificity : 0.9085          
         Pos Pred Value : 0.9163          
         Neg Pred Value : 0.9932          
             Prevalence : 0.5018          
         Detection Rate : 0.4988          
   Detection Prevalence : 0.5443          
      Balanced Accuracy : 0.9512          
                                          
       &#39;Positive&#39; Class : e               
                                          </code></pre>
<pre><code>Setting levels: control = e, case = p
Setting direction: controls &gt; cases</code></pre>
<p><img src="figure/NaiveBayes.Rmd/NB%20in%20R-4.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-no-spaces-NB-in-R-4">
Past versions of “NB in R-4.png”
</button>
</p>
<div id="fig-no-spaces-NB-in-R-4" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/figure/NaiveBayes.Rmd/NB in R-4.png" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre><code>Area under the curve: 0.9976</code></pre>
<p><img src="figure/NaiveBayes.Rmd/NB%20in%20R-5.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-no-spaces-NB-in-R-5">
Past versions of “NB in R-5.png”
</button>
</p>
<div id="fig-no-spaces-NB-in-R-5" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/anthonyhung/MSTPsummerstatistics/blob/ecd13809c9538658ffd2ef75bbf41fd24ac2e39d/docs/figure/NaiveBayes.Rmd/NB in R-5.png" target="_blank">ecd1380</a>
</td>
<td>
Anthony Hung
</td>
<td>
2020-05-09
</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We can appreciate that the algorithm performs fairly well in each iteration (&gt;90% accuracy), meaning we can be pretty confident that it is not overfitting our data.</p>
<p>To better understand what the algorithm has determined (i.e. the individual event probabilities and prior probabilities that have been estimated), we can examine the output for one of the iterations of our cross validation (treating group 1 as our test set). Do you notice any patterns that jump out at you? Which variables do you think are most informative in terms of differentiating between edible and poisonous mushrooms?</p>
<pre class="r"><code>#select which group is our test data and define our training/testing data
test_i &lt;- which(folds_i == 1)
train_data &lt;- mush_data[-test_i, ]
test_data &lt;- mush_data[test_i, ]

#train classifier
classifier_nb &lt;- naiveBayes(train_data[,-1], train_data$class)

#use classifier to predict classes of test data
nb_pred &lt;- predict(classifier_nb, type = &#39;class&#39;, newdata = test_data)

#assess the accuracy of the classifier on the test data using a confusion matrix
print(confusionMatrix(nb_pred,test_data$class))</code></pre>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction   e   p
         e 836  91
         p   2 696
                                          
               Accuracy : 0.9428          
                 95% CI : (0.9303, 0.9536)
    No Information Rate : 0.5157          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.885           
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.9976          
            Specificity : 0.8844          
         Pos Pred Value : 0.9018          
         Neg Pred Value : 0.9971          
             Prevalence : 0.5157          
         Detection Rate : 0.5145          
   Detection Prevalence : 0.5705          
      Balanced Accuracy : 0.9410          
                                          
       &#39;Positive&#39; Class : e               
                                          </code></pre>
<pre class="r"><code>#print a summary of the classifier
print(classifier_nb)</code></pre>
<pre><code>
Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = train_data[, -1], y = train_data$class)

A-priori probabilities:
train_data$class
        e         p 
0.5185413 0.4814587 

Conditional probabilities:
                cap.shape
train_data$class           b           c           f           k           s
               e 0.097032641 0.000000000 0.381899110 0.055489614 0.007715134
               p 0.012144455 0.001278364 0.395973154 0.153403643 0.000000000
                cap.shape
train_data$class           x
               e 0.457863501
               p 0.437200384

                cap.surface
train_data$class           f           g           s           y
               e 0.374777448 0.000000000 0.273590504 0.351632047
               p 0.197826782 0.001278364 0.356983062 0.443911793

                cap.color
train_data$class           b           c           e           g           n
               e 0.012462908 0.007418398 0.148664688 0.243620178 0.298516320
               p 0.029721956 0.003195909 0.224033237 0.210930010 0.259827421
                cap.color
train_data$class           p           r           u           w           y
               e 0.013649852 0.003857567 0.004154303 0.172403561 0.095252226
               p 0.022371365 0.000000000 0.000000000 0.079258549 0.170661553

                bruises
train_data$class         f         t
               e 0.3548961 0.6451039
               p 0.8443592 0.1556408

                odor
train_data$class          a          c          f          l          m
               e 0.09169139 0.00000000 0.00000000 0.09495549 0.00000000
               p 0.00000000 0.05017578 0.55193353 0.00000000 0.01022691
                odor
train_data$class          n          p          s          y
               e 0.81335312 0.00000000 0.00000000 0.00000000
               p 0.02972196 0.06295941 0.14988814 0.14509428

                gill.attachment
train_data$class           a           f
               e 0.045994065 0.954005935
               p 0.005113455 0.994886545

                gill.spacing
train_data$class          c          w
               e 0.70593472 0.29406528
               p 0.96963886 0.03036114

                gill.size
train_data$class          b          n
               e 0.92818991 0.07181009
               p 0.43560243 0.56439757

                gill.color
train_data$class           b           e           g           h           k
               e 0.000000000 0.024925816 0.060534125 0.048961424 0.082492582
               p 0.440396293 0.000000000 0.131032279 0.134547779 0.014062001
                gill.color
train_data$class           n           o           p           r           u
               e 0.217804154 0.016023739 0.200890208 0.000000000 0.105341246
               p 0.028124001 0.000000000 0.163630553 0.006072228 0.012464046
                gill.color
train_data$class           w           y
               e 0.227596439 0.015430267
               p 0.063598594 0.006072228

                stalk.shape
train_data$class         e         t
               e 0.3878338 0.6121662
               p 0.4880153 0.5119847

                stalk.root
train_data$class          ?          b          c          e          r
               e 0.17833828 0.44985163 0.11869436 0.20949555 0.04362018
               p 0.44646852 0.47778843 0.01278364 0.06295941 0.00000000

                stalk.surface.above.ring
train_data$class           f           k           s           y
               e 0.100296736 0.035905045 0.859940653 0.003857567
               p 0.034196229 0.571108981 0.392138063 0.002556727

                stalk.surface.below.ring
train_data$class          f          k          s          y
               e 0.11186944 0.03620178 0.80445104 0.04747774
               p 0.03323746 0.55640780 0.39149888 0.01885586

                stalk.color.above.ring
train_data$class           b           c           e           g           n
               e 0.000000000 0.000000000 0.024035608 0.137388724 0.003857567
               p 0.107062959 0.010226910 0.000000000 0.000000000 0.111217641
                stalk.color.above.ring
train_data$class           o           p           w           y
               e 0.045994065 0.129970326 0.658753709 0.000000000
               p 0.000000000 0.342921061 0.426014701 0.002556727

                stalk.color.below.ring
train_data$class           b           c           e           g           n
               e 0.000000000 0.000000000 0.024925816 0.139465875 0.016023739
               p 0.110258869 0.010226910 0.000000000 0.000000000 0.112496005
                stalk.color.below.ring
train_data$class           o           p           w           y
               e 0.045994065 0.129080119 0.644510386 0.000000000
               p 0.000000000 0.340044743 0.421860019 0.005113455

                veil.type
train_data$class p
               e 1
               p 1

                veil.color
train_data$class           n           o           w           y
               e 0.024332344 0.021661721 0.954005935 0.000000000
               p 0.000000000 0.000000000 0.997443273 0.002556727

                ring.number
train_data$class          n          o          t
               e 0.00000000 0.86795252 0.13204748
               p 0.01022691 0.97091723 0.01885586

                ring.type
train_data$class          e          f          l          n          p
               e 0.24718101 0.01186944 0.00000000 0.00000000 0.74094955
               p 0.44902525 0.00000000 0.33493129 0.01022691 0.20581655

                spore.print.color
train_data$class          b          h          k          n          o
               e 0.01038576 0.01186944 0.38427300 0.41305638 0.01127596
               p 0.00000000 0.40651965 0.05496964 0.05816555 0.00000000
                spore.print.color
train_data$class          r          u          w          y
               e 0.00000000 0.01246291 0.14421365 0.01246291
               p 0.01885586 0.00000000 0.46148929 0.00000000

                population
train_data$class          a          c          n          s          v
               e 0.09376855 0.07210682 0.09436202 0.21038576 0.28011869
               p 0.00000000 0.01502077 0.00000000 0.09395973 0.72962608
                population
train_data$class          y
               e 0.24925816
               p 0.16139342

                habitat
train_data$class           d           g           l           m           p
               e 0.440059347 0.337091988 0.058160237 0.061424332 0.030860534
               p 0.322786833 0.187919463 0.150527325 0.008948546 0.259827421
                habitat
train_data$class           u           w
               e 0.023442136 0.048961424
               p 0.069990412 0.000000000</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.3 (2020-02-29)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Catalina 10.15.4

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] pROC_1.16.2     caret_6.0-86    lattice_0.20-38 e1071_1.7-3    
[5] cowplot_1.0.0   ggplot2_3.3.0  

loaded via a namespace (and not attached):
 [1] tidyselect_1.0.0     xfun_0.12            reshape2_1.4.3      
 [4] purrr_0.3.4          splines_3.6.3        colorspace_1.4-1    
 [7] vctrs_0.2.4          generics_0.0.2       stats4_3.6.3        
[10] htmltools_0.4.0      yaml_2.2.1           prodlim_2019.11.13  
[13] survival_3.1-8       rlang_0.4.5          ModelMetrics_1.2.2.2
[16] later_1.0.0          pillar_1.4.3         glue_1.4.0          
[19] withr_2.1.2          foreach_1.4.7        lifecycle_0.2.0     
[22] plyr_1.8.5           lava_1.6.6           stringr_1.4.0       
[25] timeDate_3043.102    munsell_0.5.0        gtable_0.3.0        
[28] workflowr_1.5.0      recipes_0.1.11       codetools_0.2-16    
[31] evaluate_0.14        labeling_0.3         knitr_1.26          
[34] httpuv_1.5.2         class_7.3-15         Rcpp_1.0.4.6        
[37] promises_1.1.0       scales_1.1.0         backports_1.1.6     
[40] ipred_0.9-9          farver_2.0.3         fs_1.3.1            
[43] digest_0.6.25        stringi_1.4.5        dplyr_0.8.5         
[46] rprojroot_1.3-2      tools_3.6.3          magrittr_1.5        
[49] tibble_3.0.1         crayon_1.3.4         whisker_0.4         
[52] pkgconfig_2.0.3      MASS_7.3-51.5        ellipsis_0.3.0      
[55] Matrix_1.2-18        data.table_1.12.8    lubridate_1.7.4     
[58] gower_0.2.1          assertthat_0.2.1     rmarkdown_1.18      
[61] iterators_1.0.12     R6_2.4.1             rpart_4.1-15        
[64] nnet_7.3-12          nlme_3.1-144         git2r_0.26.1        
[67] compiler_3.6.3      </code></pre>
</div>
</div>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
